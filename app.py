import streamlit as st
import openai
from pinecone import Pinecone

# -------------------------------
# ğŸ” Configuration API
# -------------------------------

openai.api_key = st.secrets["OPENAI_API_KEY"]
pc = Pinecone(api_key=st.secrets["PINECONE_API_KEY"])

index = pc.Index("quickstart")  # remplace par le nom exact de ton index Pinecone


# -------------------------------
# ğŸŒ Interface Streamlit
# -------------------------------

st.set_page_config(page_title="IA LÃ©on - Recherche sÃ©mantique - Neo2", layout="wide")

# --- ğŸ”¹ Header stylisÃ©
st.markdown("""
<div style="display: flex; justify-content: space-between; align-items: center;">
  <h1 style="margin-bottom: 0;">ğŸ” Recherche sÃ©mantique â€“ Neo2</h1>
  <span style="background-color: #e0e0e0; padding: 6px 12px; border-radius: 8px; font-weight: bold; color: #333;">
    Version 1.0
  </span>
</div>
""", unsafe_allow_html=True)

# --- ğŸ“˜ Sections sidebar

with st.sidebar.expander("ğŸ¤– Qui est LÃ©on ?"):
    st.markdown("""
    <div style="font-size: 13px;">
        <p><strong>LÃ©on</strong> est une IA dÃ©veloppÃ©e par <strong>Neo2</strong> et alimentÃ©e de milliers de dossiers de compÃ©tences collectÃ©s sur 15 ans.</p>
        <ul>
            <li>Il vous aide Ã  retrouver des informations tirÃ©es des expÃ©riences professionnelles passÃ©es des profils Neo2.</li>
            <li>Il ne connaÃ®t <strong>ni les parcours acadÃ©miques</strong>, <strong>ni les soft skills</strong> des profils.</li>
            <li>Il se base exclusivement sur les expÃ©riences professionnelles, qu'elles aient Ã©tÃ© rÃ©alisÃ©es via Neo2 ou non.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)


with st.sidebar.expander("ğŸ“˜ Comment l'utiliser ?"):
    st.markdown("""
    <div style="font-size: 13px;">
        <p><strong>LÃ©on accepte trois types de requÃªtes :</strong></p>
        <ul>
            <li>Le nom d'une entreprise spÃ©cifique</li>
            <li>Un type de compÃ©tence en particulier</li>
            <li>Un descriptif plus exhaustif dâ€™un profil recherchÃ©</li>
        </ul>
        <p><strong>Plus la requÃªte est riche</strong>, plus les rÃ©sultats seront pertinents.</p>
        <p>LÃ©on identifie les <strong>3 expÃ©riences professionnelles</strong> les plus pertinentes et les explique.</p>
    </div>
    """, unsafe_allow_html=True)


with st.sidebar.expander("ğŸŒ± FrugalitÃ©"):
    st.markdown("""
    <div style="font-size: 13px;">
        <p><strong>Veuillez utiliser LÃ©on avec parcimonie :</strong></p>
        <ul>
            <li>Chaque requÃªte coÃ»te un peu d'argent</li>
            <li>Et surtout consomme des ressources (eau, Ã©nergie pour le refroidissement des serveurs)</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)


# -------------------------------
# ğŸ¯ Interface principale
# -------------------------------

# --- ğŸ” Bloc requÃªte utilisateur
st.markdown("## ğŸ§¾ RequÃªte")
query = st.text_input("Formulez votre recherche :", placeholder="Ex.: 'ExpÃ©rience en conception de tuyauterie industrielle et maÃ®trise du module LICAD'")

if query:
    with st.spinner("Recherche en cours..."):
        try:
            # Embedding
            response = openai.embeddings.create(
                input=query,
                model="text-embedding-3-small"
            )
            vector = response.data[0].embedding

            # Pinecone query
            results = index.query(
                vector=vector,
                top_k=3,
                include_metadata=True,
                namespace="CV_test200_doc_docx"
            )

            # Prompt construction
            system_prompt = (
                "Tu es un agent qui fait du matching entre des expÃ©riences professionnelles "
                "tirÃ©es de CV et une requÃªte passÃ©e par un utilisateur. Ton objectif est "
                "d'expliquer pourquoi au moins une de ces expÃ©riences correspond bien Ã  la requÃªte. Il peut y avoir trois types de requÃªtes. Soit un descriptif d'un profil, soit le nom d'une entreprise particuliÃ¨re soit un type de compÃ©tence particulier. Soit nuancÃ© et capable d'Ã©valuer la pertinence du matching. "
            )

            experiences_text = ""
            for i, match in enumerate(results["matches"], start=1):
                meta = match.get("metadata", {})
                experiences_text += f"ExpÃ©rience {i}:\n"
                for key, value in meta.items():
                    experiences_text += f"{key}: {value}\n"
                experiences_text += "\n"

            user_message = f"RequÃªte : {query}\n\nExpÃ©riences :\n{experiences_text.strip()}"

            # LLM Call
            chat_completion = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.2
            )

            # --- ğŸ§  Bloc LLM
            st.markdown("## ğŸ§  InterprÃ©tation de LÃ©on")
            st.markdown(f"""
            <div style="border: 1px solid #DDD; padding: 15px; border-radius: 8px; background-color: #d6d7f2;color: #333;">
            {chat_completion.choices[0].message.content}
            </div>
            """, unsafe_allow_html=True)

            # --- ğŸ“„ Bloc expÃ©riences
            st.markdown("## ğŸ“„ ExpÃ©riences similaires trouvÃ©es")
            for i, match in enumerate(results["matches"], start=1):
                meta = match.get("metadata", {})
                score = round(match.get("score", 0), 3)

                entreprise = meta.get("entreprise", "Entreprise inconnue")
                fonction = meta.get("poste", "Fonction inconnue")
                ref = meta.get("source", "RÃ©f. inconnue")
                duree = meta.get("duree_mois", "DurÃ©e inconnue")

                title = f"ğŸ”¹ EXPERIENCE {i} : {entreprise} | {fonction} | {duree}  | {ref}| Score: {score}"
                with st.expander(title):
                    for key, value in meta.items():
                        st.markdown(f"**{key}** : {value}")
        except Exception as e:
            st.error(f"Erreur lors de la recherche : {e}")

        # --- ğŸ“ Option de follow-up : rÃ©daction dâ€™un mÃ©mo
    st.markdown("## ğŸ“ MÃ©mo personnalisÃ©")
    st.markdown("**Voulez-vous que je rÃ©dige un mÃ©mo commercial prÃªt Ã  envoyer au client pour convaincre que nous avons les bons profils rÃ©fÃ©rencÃ©s chez Neo2 par rapport Ã  la requÃªte?**")

    # Boutons pour chaque expÃ©rience
    col1, col2, col3 = st.columns(3)
    memo_requested = None

    with col1:
        if st.button("ğŸ§‘â€ğŸ’¼ ExpÃ©rience 1"):
            memo_requested = 0
    with col2:
        if st.button("ğŸ‘¨â€ğŸ’¼ ExpÃ©rience 2"):
            memo_requested = 1
    with col3:
        if st.button("ğŸ‘©â€ğŸ’¼ ExpÃ©rience 3"):
            memo_requested = 2

    if memo_requested is not None:
        try:
            selected_match = results["matches"][memo_requested]
            selected_meta = selected_match.get("metadata", {})
            
            # GÃ©nÃ¨re le descriptif complet Ã  partir des mÃ©tadonnÃ©es
            experience_description = ""
            for key, value in selected_meta.items():
                experience_description += f"{key}: {value}\n"

            # Placeholder du system prompt (modifiable)
            memo_system_prompt = (
                "Tu es un agent qui incarne un chasseur de tÃªte. Tu as pour objectif de rÃ©diger un mÃ©mo qui justife pourquoi une requÃªte d'un client correspond Ã  une expÃ©rience professionnelle choisie. On va te fournir une requÃªte qui peut Ãªtre soit un descriptif d'un profil professionnel recherchÃ©, soit le nom d'une entreprise particuliÃ¨re soit un type de compÃ©tence particulier. Et on va te fournir Ã©galement le descriptif d'une expÃ©rience professionnelle qui, Ã  priori, correspond Ã  la requÃªte. Tu dois argumentr et justifier de la pertinence du matching, tout en gardant un ton factuel et professionnel. Tu te contentes de rÃ©diger le mÃ©mo. La rÃ©ponse doit faire 200 mots maximum. Tu commences avec ce dÃ©but de phrase 'Parmis nos profils rÃ©fÃ©rencÃ©s, nous en avons un qui correspond particuliÃ¨rement bien Ã  votre requÃªte. En effet [...] '"
                
            )

            user_input_for_memo = f"RequÃªte : {query}\n\nExpÃ©rience :\n{experience_description.strip()}"

            with st.spinner("âœï¸ RÃ©daction du mÃ©mo en cours..."):
                memo_response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": memo_system_prompt},
                        {"role": "user", "content": user_input_for_memo}
                    ],
                    temperature=0.3
                )

            memo_text = memo_response.choices[0].message.content

            st.markdown("### âœï¸ MÃ©mo gÃ©nÃ©rÃ© :")
            st.text_area("MÃ©mo", memo_text, height=300)

        except Exception as e:
            st.error(f"Erreur lors de la gÃ©nÃ©ration du mÃ©mo : {e}")
