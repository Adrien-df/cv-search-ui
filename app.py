# Ajout de st.session_state pour que le clic sur les boutons XP fonctionne 
# entre deux runs Streamlit

import streamlit as st
import openai
from pinecone import Pinecone

# -------------------------------
# ğŸ” Configuration API
# -------------------------------

openai.api_key = st.secrets["OPENAI_API_KEY"]
pc = Pinecone(api_key=st.secrets["PINECONE_API_KEY"])

# Initialisation de l'Ã©tat pour le mÃ©mo et les rÃ©sultats
if "memo_requested" not in st.session_state:
    st.session_state.memo_requested = None
if "results" not in st.session_state:
    st.session_state.results = None
if "memo_text" not in st.session_state:
    st.session_state.memo_text = None

# -------------------------------
# ğŸŒ Interface Streamlit
# -------------------------------

st.set_page_config(page_title="IA LÃ©on - Recherche sÃ©mantique - Neo2", layout="wide")

# --- ğŸ”¹ Header stylisÃ©
st.markdown("""
<div style="display: flex; justify-content: space-between; align-items: center;">
  <h1 style="margin-bottom: 0;">ğŸ” Recherche sÃ©mantique â€“ Neo2</h1>
  <span style="background-color: #e0e0e0; padding: 6px 12px; border-radius: 8px; font-weight: bold; color: #333;">
    Version 1.0
  </span>
</div>
""", unsafe_allow_html=True)

# Bandeau d'information en haut
st.markdown("""
<div style="
    background: linear-gradient(90deg, #3498db, #2980b9);
    color: white;
    padding: 12px 15px;
    border-radius: 8px;
    margin-bottom: 20px;
    border-left: 4px solid #2471a3;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
">
    <div style="display: flex; align-items: center;">
        <span style="font-size: 16px; margin-right: 8px;">âš ï¸</span>
        <div style="font-size: 13px; line-height: 1.4;">
            <strong>Note pour les premiers utilisateurs :</strong> il s'agit d'une premiÃ¨re version qui est limitÃ©e dans plusieurs aspects. La requÃªte en peut Ãªtre faite que sur 5000 DC max. (env. 20% de la base de DC); les profils aprÃ¨s mai 2025 ne s'y retrouvent pas; le matching peut parfois Ãªtre mauvais. L'objectif est que vous, utilisateurs finaux, puissiez tester et faire des premiers retours. Ainsi, on pourra valider si l'outil est pertinent pour les argumentaires commerciaux, ou si la plus-value est limitÃ©e. Vous pouvez faire vos retours dans ce <a href="https://docs.google.com/forms/d/e/1FAIpQLSd7oG1y-Xh_-_tS4K20qCC85l7Ia2tbNZ7Q_p-6gpcGndM-Vg/viewform?usp=dialog" target="_blank" style="color: #fff; text-decoration: underline;">formulaire anonyme</a>.
        </div>
    </div>
</div>
""", unsafe_allow_html=True)

# --- ğŸ“˜ Sections sidebar

with st.sidebar.expander("ğŸ¤– Qui est LÃ©on ?"):
    st.markdown("""
    <div style="font-size: 13px;">
        <p><strong>LÃ©on</strong> est une IA dÃ©veloppÃ©e par <strong>Neo2</strong> et alimentÃ©e de milliers de dossiers de compÃ©tences collectÃ©s sur 15 ans.</p>
        <ul>
            <li>Il vous aide Ã  retrouver des informations tirÃ©es des expÃ©riences professionnelles passÃ©es des profils Neo2.</li>
            <li>Il ne connaÃ®t <strong>ni les parcours acadÃ©miques</strong>, <strong>ni les soft skills</strong> des profils.</li>
            <li>Il se base exclusivement sur les expÃ©riences professionnelles, qu'elles aient Ã©tÃ© rÃ©alisÃ©es via Neo2 ou non.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)


with st.sidebar.expander("ğŸ“˜ Comment l'utiliser ?"):
    st.markdown("""
    <div style="font-size: 13px;">
        <p><strong>LÃ©on accepte trois grands types de requÃªtes :</strong></p>
        <ul>
            <li>Le nom d'une entreprise spÃ©cifique</li>
            <li>Un type de compÃ©tence en particulier</li>
            <li>Un descriptif plus exhaustif d'un profil recherchÃ©</li>
        </ul>
        <p><strong>Plus la requÃªte est riche</strong>, plus les rÃ©sultats seront pertinents.</p>
        <p>LÃ©on identifie les <strong>10 expÃ©riences professionnelles</strong> les plus pertinentes et explique pourquoi au moins une d'entre elles est particuliÃ¨rement pertinente.</p>
    </div>
    """, unsafe_allow_html=True)


with st.sidebar.expander("ğŸŒ± FrugalitÃ©"):
    st.markdown("""
    <div style="font-size: 13px;">
        <p><strong>Veuillez utiliser LÃ©on avec parcimonie :</strong></p>
        <ul>
            <li>Chaque requÃªte coÃ»te un peu d'argent</li>
            <li>Et surtout consomme des ressources (eau, Ã©nergie pour le refroidissement des serveurs)</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

# -------------------------------
# ğŸŒŸ Interface principale
# -------------------------------



# SÃ©lection de la base de donnÃ©es
st.markdown("### ğŸ—‚ï¸ Choix de la base de donnÃ©es DC")
database_choice = st.radio(
    "SÃ©lectionnez la base de donnÃ©es Ã  utiliser :",
    ("2500 DC les + rÃ©cents", "5000 DC"),
    help="Choisissez entre la base restreinte aux profils les plus rÃ©cents ou une base avec plus d'expÃ©riences mais ne comportant que les dossiers commenÃ§ant par A, B ou C"
)


st.markdown("## ğŸ“Ÿ RequÃªte")
query = st.text_input("Formulez votre recherche :", placeholder="Ex.: 'ExpÃ©rience en...'")
mot_cle_obligatoire = st.text_input("(Champ facultatif) Mot-clÃ© Ã  retrouver obligatoirement dans le descriptif :", placeholder="Ex.: EDF")
lancer_recherche = st.button("ğŸ” Lancer la recherche")

if query and lancer_recherche:
    # RÃ©initialiser les Ã©tats lors d'une nouvelle recherche
    st.session_state.memo_requested = None
    st.session_state.memo_text = None
    
    with st.spinner("Recherche en cours..."):
        try:
            # Configuration de l'index et namespace selon le choix
            if database_choice == "5000 DC":
                index = pc.Index("neo2-dc-v1")
                namespace = "V1"
            else:  # "2500 DC les + rÃ©cents"
                index = pc.Index("neo2-dc-v2")
                namespace = "2000_recents_avec_synthese_V2"
            
            response = openai.embeddings.create(input=query, model="text-embedding-3-small")
            vector = response.data[0].embedding

            brut_results = index.query(
                vector=vector, top_k=10, include_metadata=True, namespace=namespace
            )

            matches_filtrÃ©s = [
                m for m in brut_results.matches
                if "descriptif_complet" in m.metadata and mot_cle_obligatoire.lower() in m.metadata["descriptif_complet"].lower()
            ] if mot_cle_obligatoire else brut_results.matches

            results = {"matches": matches_filtrÃ©s}
            st.session_state.results = results

            if mot_cle_obligatoire:
                st.success(f"{len(results['matches'])} rÃ©sultats trouvÃ©s avec le mot-clÃ© '{mot_cle_obligatoire}'.")

            system_prompt = (
                "Tu es un agent qui fait du matching entre des expÃ©riences professionnelles "
                "tirÃ©es de CV et une requÃªte passÃ©e par un utilisateur. Ton objectif est "
                "d'expliquer pourquoi au moins une de ces expÃ©riences correspond bien Ã  la requÃªte. Il peut y avoir trois types de requÃªtes. Soit un descriptif d'un profil, soit le nom d'une entreprise particuliÃ¨re soit un type de compÃ©tence particulier. Soit nuancÃ© et capable d'Ã©valuer la pertinence du matching. "
            )

            experiences_text = ""
            for i, match in enumerate(results["matches"], start=1):
                meta = match.get("metadata", {})
                experiences_text += f"ExpÃ©rience {i}:"
                for key, value in meta.items():
                    experiences_text += f"{key}: {value}"
                experiences_text += "\n"

            user_message = f"RequÃªte : {query}\n\nExpÃ©riences :\n{experiences_text.strip()}"

            chat_completion = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.2
            )

            st.markdown("## ğŸ§  InterprÃ©tation de LÃ©on")
            st.markdown(f"""
            <div style="border: 1px solid #DDD; padding: 15px; border-radius: 8px; background-color: #d6d7f2;color: #333;">
            {chat_completion.choices[0].message.content}
            </div>
            """, unsafe_allow_html=True)

            st.markdown("## ğŸ“„ ExpÃ©riences similaires trouvÃ©es")
            for i, match in enumerate(results["matches"], start=1):
                meta = match.get("metadata", {})
                score = round(match.get("score", 0), 3)
                titre = f"ğŸ”¹ EXPERIENCE {i} : {meta.get('entreprise', 'Inconnue')} | {meta.get('poste', 'Inconnue')} | DurÃ©e : {meta.get('duree_mois', 'Inconnue')} mois | Source : {meta.get('source', 'Inconnue')} mois | Score: {score}"
                with st.expander(titre):
                    st.markdown(f"{meta.get('descriptif_complet', 'Inconnue')} ")

        except Exception as e:
            st.error(f"Erreur lors de la recherche : {e}")

# --- ğŸ“ MÃ©mo personnalisÃ© (affichÃ© seulement si des rÃ©sultats existent)
if st.session_state.results and len(st.session_state.results["matches"]) > 0:
    st.markdown("## ğŸ“ MÃ©mo personnalisÃ©")
    st.markdown("**Cliquez sur une expÃ©rience pour gÃ©nÃ©rer un mÃ©mo Ã  envoyer au client :**")

    # Afficher seulement le nombre de boutons correspondant aux rÃ©sultats
    num_results = len(st.session_state.results["matches"])
    cols = st.columns(min(num_results, 10))  # Maximum 10 colonnes
    
    for i in range(num_results):
        col_index = i % 10  # Pour gÃ©rer le cas oÃ¹ il y a plus de 10 rÃ©sultats
        if i < 10:  # Limiter Ã  10 boutons maximum
            if cols[col_index].button(f"XP {i+1}"):
                st.session_state.memo_requested = i

    # GÃ©nÃ©ration du mÃ©mo si une expÃ©rience a Ã©tÃ© sÃ©lectionnÃ©e
    if st.session_state.memo_requested is not None:
        try:
            selected_match = st.session_state.results["matches"][st.session_state.memo_requested]
            selected_meta = selected_match.get("metadata", {})
            experience_description = "\n".join([f"{k}: {v}" for k, v in selected_meta.items()])

            memo_system_prompt = (
                "Tu es un agent qui incarne un chasseur de tÃªte. Tu as pour objectif de rÃ©diger un mÃ©mo qui justife pourquoi une requÃªte d'un client correspond Ã  une expÃ©rience professionnelle choisie. On va te fournir une requÃªte qui peut Ãªtre soit un descriptif d'un profil professionnel recherchÃ©, soit le nom d'une entreprise particuliÃ¨re soit un type de compÃ©tence particulier. Et on va te fournir Ã©galement le descriptif d'une expÃ©rience professionnelle qui, Ã  priori, correspond Ã  la requÃªte. Tu dois argumentr et justifier de la pertinence du matching, tout en gardant un ton factuel et professionnel. Tu te contentes de rÃ©diger le mÃ©mo. La rÃ©ponse doit faire 200 mots maximum. Tu commences avec ce dÃ©but de phrase 'Parmis nos profils rÃ©fÃ©rencÃ©s, nous en avons un qui correspond particuliÃ¨rement bien Ã  votre requÃªte. En effet [...] '"
            )

            user_input_for_memo = f"RequÃªte : {query}\n\nExpÃ©rience :\n{experience_description.strip()}"

            # GÃ©nÃ©rer le mÃ©mo seulement si ce n'est pas dÃ©jÃ  fait pour cette expÃ©rience
            if st.session_state.memo_text is None:
                with st.spinner("âœï¸ RÃ©daction du mÃ©mo en cours..."):
                    memo_response = openai.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": memo_system_prompt},
                            {"role": "user", "content": user_input_for_memo}
                        ],
                        temperature=0.3
                    )
                st.session_state.memo_text = memo_response.choices[0].message.content

            st.markdown("### âœï¸ MÃ©mo gÃ©nÃ©rÃ© :")
            st.text_area("MÃ©mo", st.session_state.memo_text, height=300)

        except Exception as e:
            st.error(f"Erreur lors de la gÃ©nÃ©ration du mÃ©mo : {e}")