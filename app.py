# Ajout de st.session_state pour que le clic sur les boutons XP fonctionne 
# entre deux runs Streamlit

import streamlit as st
import openai
from pinecone import Pinecone

# -------------------------------
# ğŸ” Configuration API
# -------------------------------

openai.api_key = st.secrets["OPENAI_API_KEY"]
pc = Pinecone(api_key=st.secrets["PINECONE_API_KEY"])

index = pc.Index("neo2-dc-v1")  # remplace par le nom exact de ton index Pinecone

# Initialisation de l'Ã©tat pour le mÃ©mo et les rÃ©sultats
if "memo_requested" not in st.session_state:
    st.session_state.memo_requested = None
if "results" not in st.session_state:
    st.session_state.results = None
if "memo_text" not in st.session_state:
    st.session_state.memo_text = None

# -------------------------------
# ğŸŒ Interface Streamlit
# -------------------------------

st.set_page_config(page_title="IA LÃ©on - Recherche sÃ©mantique - Neo2", layout="wide")

# --- ğŸ”¹ Header stylisÃ©
st.markdown("""
<div style="display: flex; justify-content: space-between; align-items: center;">
  <h1 style="margin-bottom: 0;">ğŸ” Recherche sÃ©mantique â€“ Neo2</h1>
  <span style="background-color: #e0e0e0; padding: 6px 12px; border-radius: 8px; font-weight: bold; color: #333;">
    Version 1.0
  </span>
</div>
""", unsafe_allow_html=True)

# --- ğŸ“˜ Sections sidebar

with st.sidebar.expander("ğŸ¤– Qui est LÃ©on ?"):
    st.markdown("""
    <div style="font-size: 13px;">
        <p><strong>LÃ©on</strong> est une IA dÃ©veloppÃ©e par <strong>Neo2</strong> et alimentÃ©e de milliers de dossiers de compÃ©tences collectÃ©s sur 15 ans.</p>
        <ul>
            <li>Il vous aide Ã  retrouver des informations tirÃ©es des expÃ©riences professionnelles passÃ©es des profils Neo2.</li>
            <li>Il ne connaÃ®t <strong>ni les parcours acadÃ©miques</strong>, <strong>ni les soft skills</strong> des profils.</li>
            <li>Il se base exclusivement sur les expÃ©riences professionnelles, qu'elles aient Ã©tÃ© rÃ©alisÃ©es via Neo2 ou non.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)


with st.sidebar.expander("ğŸ“˜ Comment l'utiliser ?"):
    st.markdown("""
    <div style="font-size: 13px;">
        <p><strong>LÃ©on accepte trois types de requÃªtes :</strong></p>
        <ul>
            <li>Le nom d'une entreprise spÃ©cifique</li>
            <li>Un type de compÃ©tence en particulier</li>
            <li>Un descriptif plus exhaustif d'un profil recherchÃ©</li>
        </ul>
        <p><strong>Plus la requÃªte est riche</strong>, plus les rÃ©sultats seront pertinents.</p>
        <p>LÃ©on identifie les <strong>3 expÃ©riences professionnelles</strong> les plus pertinentes et les explique.</p>
    </div>
    """, unsafe_allow_html=True)


with st.sidebar.expander("ğŸŒ± FrugalitÃ©"):
    st.markdown("""
    <div style="font-size: 13px;">
        <p><strong>Veuillez utiliser LÃ©on avec parcimonie :</strong></p>
        <ul>
            <li>Chaque requÃªte coÃ»te un peu d'argent</li>
            <li>Et surtout consomme des ressources (eau, Ã©nergie pour le refroidissement des serveurs)</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

# -------------------------------
# ğŸŒŸ Interface principale
# -------------------------------

st.markdown("## ğŸ“Ÿ RequÃªte")
query = st.text_input("Formulez votre recherche :", placeholder="Ex.: 'ExpÃ©rience en...'")
mot_cle_obligatoire = st.text_input("Mot-clÃ© obligatoire dans le descriptif :", placeholder="Ex.: EDF")
lancer_recherche = st.button("ğŸ” Lancer la recherche")

if query and lancer_recherche:
    # RÃ©initialiser les Ã©tats lors d'une nouvelle recherche
    st.session_state.memo_requested = None
    st.session_state.memo_text = None
    
    with st.spinner("Recherche en cours..."):
        try:
            response = openai.embeddings.create(input=query, model="text-embedding-3-small")
            vector = response.data[0].embedding

            brut_results = index.query(
                vector=vector, top_k=10, include_metadata=True, namespace="V1"
            )

            matches_filtrÃ©s = [
                m for m in brut_results.matches
                if "descriptif_complet" in m.metadata and mot_cle_obligatoire.lower() in m.metadata["descriptif_complet"].lower()
            ] if mot_cle_obligatoire else brut_results.matches

            results = {"matches": matches_filtrÃ©s}
            st.session_state.results = results

            if mot_cle_obligatoire:
                st.success(f"{len(results['matches'])} rÃ©sultats trouvÃ©s avec le mot-clÃ© '{mot_cle_obligatoire}'.")

            system_prompt = (
                "Tu es un agent qui fait du matching entre des expÃ©riences professionnelles "
                "tirÃ©es de CV et une requÃªte passÃ©e par un utilisateur. Ton objectif est "
                "d'expliquer pourquoi au moins une de ces expÃ©riences correspond bien Ã  la requÃªte. Il peut y avoir trois types de requÃªtes. Soit un descriptif d'un profil, soit le nom d'une entreprise particuliÃ¨re soit un type de compÃ©tence particulier. Soit nuancÃ© et capable d'Ã©valuer la pertinence du matching. "
            )

            experiences_text = ""
            for i, match in enumerate(results["matches"], start=1):
                meta = match.get("metadata", {})
                experiences_text += f"ExpÃ©rience {i}:"
                for key, value in meta.items():
                    experiences_text += f"{key}: {value}"
                experiences_text += "\n"

            user_message = f"RequÃªte : {query}\n\nExpÃ©riences :\n{experiences_text.strip()}"

            chat_completion = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.2
            )

            st.markdown("## ğŸ§  InterprÃ©tation de LÃ©on")
            st.markdown(f"""
            <div style="border: 1px solid #DDD; padding: 15px; border-radius: 8px; background-color: #d6d7f2;color: #333;">
            {chat_completion.choices[0].message.content}
            </div>
            """, unsafe_allow_html=True)

            st.markdown("## ğŸ“„ ExpÃ©riences similaires trouvÃ©es")
            for i, match in enumerate(results["matches"], start=1):
                meta = match.get("metadata", {})
                score = round(match.get("score", 0), 3)
                titre = f"ğŸ”¹ EXPERIENCE {i} : {meta.get('entreprise', 'Inconnue')} | {meta.get('poste', 'Inconnue')} | DurÃ©e : {meta.get('duree_mois', 'Inconnue')} mois | Score: {score}"
                with st.expander(titre):
                    for key, value in meta.items():
                        st.markdown(f"**{key}** : {value}")

        except Exception as e:
            st.error(f"Erreur lors de la recherche : {e}")

# --- ğŸ“ MÃ©mo personnalisÃ© (affichÃ© seulement si des rÃ©sultats existent)
if st.session_state.results and len(st.session_state.results["matches"]) > 0:
    st.markdown("## ğŸ“ MÃ©mo personnalisÃ©")
    st.markdown("**Cliquez sur une expÃ©rience pour gÃ©nÃ©rer un mÃ©mo Ã  envoyer au client :**")

    # Afficher seulement le nombre de boutons correspondant aux rÃ©sultats
    num_results = len(st.session_state.results["matches"])
    cols = st.columns(min(num_results, 10))  # Maximum 10 colonnes
    
    for i in range(num_results):
        col_index = i % 10  # Pour gÃ©rer le cas oÃ¹ il y a plus de 10 rÃ©sultats
        if i < 10:  # Limiter Ã  10 boutons maximum
            if cols[col_index].button(f"XP {i+1}"):
                st.session_state.memo_requested = i

    # GÃ©nÃ©ration du mÃ©mo si une expÃ©rience a Ã©tÃ© sÃ©lectionnÃ©e
    if st.session_state.memo_requested is not None:
        try:
            selected_match = st.session_state.results["matches"][st.session_state.memo_requested]
            selected_meta = selected_match.get("metadata", {})
            experience_description = "\n".join([f"{k}: {v}" for k, v in selected_meta.items()])

            memo_system_prompt = (
                "Tu es un agent qui incarne un chasseur de tÃªte. Tu as pour objectif de rÃ©diger un mÃ©mo qui justife pourquoi une requÃªte d'un client correspond Ã  une expÃ©rience professionnelle choisie. On va te fournir une requÃªte qui peut Ãªtre soit un descriptif d'un profil professionnel recherchÃ©, soit le nom d'une entreprise particuliÃ¨re soit un type de compÃ©tence particulier. Et on va te fournir Ã©galement le descriptif d'une expÃ©rience professionnelle qui, Ã  priori, correspond Ã  la requÃªte. Tu dois argumentr et justifier de la pertinence du matching, tout en gardant un ton factuel et professionnel. Tu te contentes de rÃ©diger le mÃ©mo. La rÃ©ponse doit faire 200 mots maximum. Tu commences avec ce dÃ©but de phrase 'Parmis nos profils rÃ©fÃ©rencÃ©s, nous en avons un qui correspond particuliÃ¨rement bien Ã  votre requÃªte. En effet [...] '"
            )

            user_input_for_memo = f"RequÃªte : {query}\n\nExpÃ©rience :\n{experience_description.strip()}"

            # GÃ©nÃ©rer le mÃ©mo seulement si ce n'est pas dÃ©jÃ  fait pour cette expÃ©rience
            if st.session_state.memo_text is None:
                with st.spinner("âœï¸ RÃ©daction du mÃ©mo en cours..."):
                    memo_response = openai.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": memo_system_prompt},
                            {"role": "user", "content": user_input_for_memo}
                        ],
                        temperature=0.3
                    )
                st.session_state.memo_text = memo_response.choices[0].message.content

            st.markdown("### âœï¸ MÃ©mo gÃ©nÃ©rÃ© :")
            st.text_area("MÃ©mo", st.session_state.memo_text, height=300)

        except Exception as e:
            st.error(f"Erreur lors de la gÃ©nÃ©ration du mÃ©mo : {e}")